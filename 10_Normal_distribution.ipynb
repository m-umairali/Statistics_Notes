{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution\n",
    "Normal distribution also known as Gaussian Distribution (Bell curve), is a probability distribution (with the <mark>mean value located at the center and the standard deviation determining the width of the curve.</mark> ) that is commonly used in statistical analysis. It is continous probability distributions that is symmetrical around the mean, with a bell shaped curve.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://www.spcforexcel.com/files/images/nd.png\" alt=\"drawing\" width=\"45%\" height=\"200\"/>\n",
    "\n",
    "\n",
    "$f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "- f(x) is the probability density function (PDF) of the normal distribution for a given value of x.\n",
    "- σ (sigma) is the standard deviation of the distribution.\n",
    "- μ (mu) is the mean or expected value of the distribution.\n",
    "- e is the mathematical constant e (approximately 2.71828).\n",
    "- π is the mathematical constant pi (approximately 3.14159).\n",
    "- √(2π) is the square root of 2π.\n",
    "\n",
    "## Why is it important\n",
    "Commonality in nature, many natural phenomena follows a normal distribution. such as height of people, weights of objects, IQ score of population etc. \n",
    "\n",
    "Note: If you have standard deviation and mean you can easily draw the graph.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Normal Distribution (variation)\n",
    "A standard normal variate (z) is a standarized form of the normal distribution with mean 0 and std 1.\n",
    "\n",
    "\n",
    "<img src=\"https://statisticstechs.weebly.com/uploads/6/5/2/4/65248169/published/picture5_6.png?1509367351\" alt=\"drawing\" width=\"45%\" height=\"400\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Z-table\n",
    "\n",
    "A z-table, also known as a standard normal distribution table, is a table that provides probabilities for the standard normal distribution, which is a normal distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "The z-table is used to find the area under the normal distribution curve to the left of a specified value of z. Each row and column of the table corresponds to a specific z-score, and the values in the table represent the probabilities that a standard normal random variable falls below the corresponding z-score.\n",
    "\n",
    "To use a z-table, you first need to standardize the variable of interest to a standard normal distribution by subtracting the mean and dividing by the standard deviation. You can then look up the area under the curve to the left of the standardized value in the z-table.\n",
    "\n",
    "Z-tables are useful in statistics for calculating probabilities and finding critical values for hypothesis testing and confidence intervals. They are also commonly used in fields like finance and quality control to assess the probability of events occurring within a certain range of values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical rule \n",
    "\n",
    "\n",
    "<img src=\"https://1.bp.blogspot.com/-RoWUojEiszE/X7ZYOmIB1LI/AAAAAAAAAJ4/x0eRiLJvKhM0HoHNpng1sL9SH7Bd4RDFgCLcBGAsYHQ/s2508/emperic%2Brule.png\" alt=\"drawing\" width=\"45%\" height=\"400\"/>\n",
    "\n",
    "\n",
    "The empirical rule, also known as the 68-95-99.7 rule, is a statistical rule of thumb that describes the approximate distribution of a data set that follows a normal distribution.\n",
    "\n",
    "According to the empirical rule, for a normal distribution:\n",
    "\n",
    "1. Approximately 68% of the data falls within one standard deviation of the mean.\n",
    "3. Approximately 95% of the data falls within two standard deviations of the mean.\n",
    "3. Approximately 99.7% of the data falls within three standard deviations of the mean.\n",
    "- This means that if a data set is normally distributed, we can use the empirical rule to estimate the proportion of values that fall within a certain range of values.\n",
    "\n",
    "For example, if a data set has a mean of 50 and a standard deviation of 10, we can use the empirical rule to estimate that approximately 68% of the values fall between 40 and 60, approximately 95% of the values fall between 30 and 70, and approximately 99.7% of the values fall between 20 and 80.\n",
    "\n",
    "The empirical rule is a useful tool for quickly estimating the distribution of a data set and identifying any outliers or unusual values. However, it only applies to data sets that follow a normal distribution, and should be used with caution for data sets that do not meet this assumption."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of normal distribution\n",
    "1. Symmetricity: The normal distribution is symmetric around its mean, which means that the probability of observing a value above the mean is equal to the probability of observing a value below the mean."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness\n",
    "It is a statistical measure that describes the degree to which a dataset is skewed to the left or right of its mean. A dataset is said to be symmetric if it has the same shape on both sides of its center point, whereas a dataset is said to be skewed if it has a longer tail on one side than on the other.\n",
    "\n",
    "There are two types of skewness: positive skewness and negative skewness. Positive skewness occurs when the tail of the distribution is on the right side, and the mean is greater than the median. Negative skewness occurs when the tail of the distribution is on the left side, and the mean is less than the median.\n",
    "\n",
    "<img src=\"https://www.biologyforlife.com/uploads/2/2/3/9/22392738/c101b0da6ea1a0dab31f80d9963b0368_orig.png\" alt=\"drawing\" width=\"45%\" height=\"400\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use of Normal Distribution in Data Science\n",
    "1. Outlier detection\n",
    "2. Assumptions on data for ML Algorithms ==> Linear regression and GMM\n",
    "3. Hypothesis testing\n",
    "4. Centeral limit theoram"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurtosis \n",
    "Kurtosis is a measure of the shape of a probability distribution, specifically, it measures the degree of \"peakedness\" or \"flatness\" of a distribution relative to the normal distribution. A distribution with high kurtosis has a sharper peak and heavier tails than a normal distribution, while a distribution with low kurtosis has a flatter peak and lighter tails.\n",
    "\n",
    "<img src=\"https://cdn.analystprep.com/cfa-level-1-exam/wp-content/uploads/2019/08/05085139/page-64.png\" alt=\"drawing\" width=\"45%\" height=\"400\"/>\n",
    "\n",
    "\n",
    "Practical use case:\n",
    "\n",
    "Outlier detection: Kurtosis can be used to detect outliers in a dataset. Outliers are data points that are significantly different from other points in the dataset and can have a significant impact on the results of statistical analysis. A high kurtosis value can indicate the presence of outliers in the tails of the distribution.\n",
    "\n",
    "Model selection: Kurtosis can be used to choose the appropriate statistical model for a dataset. If a dataset has a high kurtosis value, it may be more appropriate to use non-parametric methods rather than traditional parametric methods.\n",
    "\n",
    "Quality control: Kurtosis can be used in quality control to detect deviations from normality in a manufacturing process. A high kurtosis value can indicate that the process is producing products with varying quality, which can lead to defects and waste.\n",
    "\n",
    "Risk management: Kurtosis is used in risk management to estimate the likelihood of extreme events, such as market crashes or natural disasters. Distributions with high kurtosis have heavier tails, meaning that extreme events are more likely to occur than in a normal distribution.\n",
    "\n",
    "Data preprocessing: Kurtosis can be used in data preprocessing to transform data into a normal distribution. This can improve the accuracy and robustness of statistical analysis by reducing the impact of outliers and deviations from normality.\n",
    "\n",
    "## Types of Kurtosis\n",
    "\n",
    "There are three types of kurtosis: leptokurtic and platykurtic.\n",
    "\n",
    "1. Leptokurtic: A leptokurtic distribution has a higher kurtosis than a normal distribution. This means that it has a sharper peak and heavier tails than a normal distribution. Leptokurtic distributions are also known as \"fat-tailed\" distributions because they have a higher probability of extreme values than a normal distribution.\n",
    "\n",
    "2. Platykurtic: A platykurtic distribution has a lower kurtosis than a normal distribution. This means that it has a flatter peak and lighter tails than a normal distribution. Platykurtic distributions are also known as \"thin-tailed\" distributions because they have a lower probability of extreme values than a normal distribution.\n",
    "\n",
    "3.  Mesokurtic\" A mesokurtic distribution has a kurtosis of zero, which means that it has the same amount of kurtosis as a normal distribution. \n",
    "\n",
    "<img src=\"https://www.simplypsychology.org/wp-content/uploads/Kurtosis.gif\" alt=\"drawing\" width=\"45%\" height=\"300\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to find the data is normal distributed or not\n",
    "1. Visual Inspection: Draw histogram, density plot, which will definitly have the bell shape curve. \n",
    "2. Q.Q Plot: A Q-Q plot is a graphical technique that compares the quantiles of the distribution to the quantiles of a normal distribution. If the points on the Q-Q plot lie close to a straight line, it indicates that the distribution is approximately normal.\n",
    "3. Statistical Tests: There are several test for find the normal distribution of the data::\n",
    "    - Shapiro-Wilk test: The Shapiro-Wilk test is a commonly used test for normality. It tests the null hypothesis that a sample comes from a normally distributed population. If the p-value of the test is less than the significance level (usually 0.05), the null hypothesis is rejected, indicating that the distribution is not normal.\n",
    "\n",
    "    - Kolmogorov-Smirnov test: The Kolmogorov-Smirnov test is another commonly used test for normality. It tests the null hypothesis that a sample comes from a normal distribution. If the p-value of the test is less than the significance level, the null hypothesis is rejected, indicating that the distribution is not normal.\n",
    "\n",
    "    - Anderson-Darling test: The Anderson-Darling test is a more powerful test for normality than the Shapiro-Wilk and Kolmogorov-Smirnov tests. It tests the null hypothesis that a sample comes from a specified normal distribution. If the p-value of the test is less than the significance level, the null hypothesis is rejected, indicating that the distribution is not normal.\n",
    "\n",
    "    - Lilliefors test: The Lilliefors test is a modified version of the Kolmogorov-Smirnov test that can be used for small sample sizes. It tests the null hypothesis that a sample comes from a normal distribution. If the p-value of the test is less than the significance level, the null hypothesis is rejected, indicating that the distribution is not normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
